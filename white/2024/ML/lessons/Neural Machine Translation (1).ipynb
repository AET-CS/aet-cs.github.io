{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFXIv9qNpKzt",
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0Piq5se2pKzx"
   },
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ekxzo6pOpKzy"
   },
   "outputs": [],
   "source": [
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
    "              \"accelerator.\")\n",
    "    if \"kaggle_secrets\" in sys.modules:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the Shakespeare data from Andrej Karpathy's [char-rnn project](https://github.com/karpathy/char-rnn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Encoder–Decoder Network for Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the spanish/english dataset\n",
    "\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, extract=True) # cache_dir defaults to ~/.keras/datasets\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "# The file might be extracted to a subdirectory within ~/.keras/datasets\n",
    "# Search for 'spa.txt' in subdirectories:\n",
    "dataset_path = Path(path).parent\n",
    "for file_path in dataset_path.rglob('spa.txt'):\n",
    "    if file_path.is_file():\n",
    "        dataset_path = file_path\n",
    "        break\n",
    "\n",
    "text = dataset_path.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
    "np.random.shuffle(pairs)\n",
    "sentences_english, sentences_spanish = zip(*pairs)  # separates the pairs into 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He will get better little by little. => Mejorará poco a poco.\n",
      "He has only four pesos. => No tiene más que cuatro pesos.\n",
      "I meet her once a week. => Me encuentro con ella una vez a la semana.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(sentences_english[i], \"=>\", sentences_spanish[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_length = 50\n",
    "\n",
    "# create a keras TextVectorization layer using the above parameters\n",
    "# then call .adapt on that layer, passing in the english sentences as parameter\n",
    "\n",
    "layer_english_vectorization = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length, pad_to_max_tokens=False, ragged=False, name = \"English_Vectorize\")\n",
    "layer_english_vectorization.adapt(sentences_english)\n",
    "\n",
    "# now do the same with the spanish -- make and adapt a layer\n",
    "# BUT for the spanish add 'starttoken' and 'endtoken' to each sentence first\n",
    "\n",
    "layer_spanish_vectorization = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length,  pad_to_max_tokens=False, ragged=False, name = \"Spanish_Vectorize\")\n",
    "layer_spanish_vectorization.adapt([f\"starttoken {s} endtoken\" for s in sentences_spanish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_english_vectorization.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'starttoken', 'endtoken', 'de', 'que', 'a', 'no', 'tom', 'la']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_spanish_vectorization.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoder = tf.constant(sentences_english[:100_000])\n",
    "X_valid_encoder = tf.constant(sentences_english[100_000:])\n",
    "X_train_decoder = tf.constant([f\"starttoken {s}\" for s in sentences_spanish[:100_000]])\n",
    "X_valid_decoder = tf.constant([f\"starttoken {s}\" for s in sentences_spanish[100_000:]])\n",
    "Y_train = layer_spanish_vectorization([f\"{s} endtoken\" for s in sentences_spanish[:100_000]])\n",
    "Y_valid = layer_spanish_vectorization([f\"{s} endtoken\" for s in sentences_spanish[100_000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_layer = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_input_layer = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this or leave it -- its the vector embedding dimension\n",
    "embed_size = 512\n",
    "\n",
    "# define encoder_vectors as the english vectorization layer applied to the encoder input layer\n",
    "encoder_vectors = layer_english_vectorization(encoder_input_layer)\n",
    "\n",
    "# define decoder vectors\n",
    "decoder_vectors = layer_spanish_vectorization(decoder_input_layer)\n",
    "\n",
    "# define an encoder_embedding_layer as a keras Embedding layer, with mask_zero = True\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=False, name = \"Encoder_Embedding\")\n",
    "\n",
    "# define an decoder_encoder_embedding_layer as a keras Embedding layer, with mask_zero = True\n",
    "\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True, name = \"Decoder_Embedding\")\n",
    "\n",
    "# finally define encoder_embeddings and decoder_embeddings as the output of the embedding layers applied to the vectors\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_vectors)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.LSTM(512, return_state=True, dropout=0.2)]                       )\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True, dropout=0.2)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Dense output_layer of the appropriate size for the spanish vocabulary\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\", name = \"Output_Dense\")\\\n",
    "\n",
    "\n",
    "# create a dropout_layer\n",
    "dropout = tf.keras.layers.Dropout(0.5, name = \"Output_Dropout\")\n",
    "\n",
    "# define Y_proba. take the decoder_outputs through the dropout layer and into the dense layer\n",
    "Y_proba = output_layer(dropout(decoder_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSparseCategoricalCrossentropy(tf.keras.losses.Loss):\n",
    "    def __init__(self, from_logits=False, name=\"masked_sparse_categorical_crossentropy\"):\n",
    "        super().__init__(reduction=\"none\", name=name)\n",
    "        self.from_logits = from_logits\n",
    "\n",
    "    @tf.function  # Compiles into a TensorFlow graph for speed\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=self.from_logits)\n",
    "        mask = tf.cast(y_true != 0, dtype=tf.float32)  # Ignore padding (0 tokens)\n",
    "\n",
    "        loss *= mask  # Apply mask\n",
    "        loss_per_sequence = tf.reduce_sum(loss, axis=-1) / tf.maximum(tf.reduce_sum(mask, axis=-1), 1.0)\n",
    "        \n",
    "        return tf.reduce_mean(loss_per_sequence)  # Average over batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSparseCategoricalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"masked_sparse_categorical_accuracy\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.correct_predictions = self.add_weight(name=\"correct\", initializer=\"zeros\")\n",
    "        self.total_valid = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Compute predicted class (argmax for probabilities or logit inputs)\n",
    "        y_pred_classes = tf.argmax(y_pred, axis=-1, output_type=tf.int64)\n",
    "\n",
    "        # Create mask where y_true != 0 (ignoring zero values)\n",
    "        mask = tf.cast(y_true != 0, dtype=tf.float32)\n",
    "\n",
    "        # Compare predictions with ground truth\n",
    "        correct = tf.cast(tf.equal(y_true, y_pred_classes), dtype=tf.float32)\n",
    "\n",
    "        # Apply mask\n",
    "        correct *= mask\n",
    "\n",
    "        # Update total count\n",
    "        self.correct_predictions.assign_add(tf.reduce_sum(correct))\n",
    "        self.total_valid.assign_add(tf.reduce_sum(mask))\n",
    "\n",
    "    def result(self):\n",
    "        return self.correct_predictions / tf.maximum(self.total_valid, 1.0)  # Avoid division by zero\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.correct_predictions.assign(0)\n",
    "        self.total_valid.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModelWithEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_path=\"best_model.keras\", patience=5):\n",
    "        \"\"\"\n",
    "        Custom callback to:\n",
    "        - Save the best model based on val_loss\n",
    "        - Stop training if val_loss doesn't improve for 'patience' epochs\n",
    "\n",
    "        Args:\n",
    "            save_path (str): Path to save the best model.\n",
    "            patience (int): Number of epochs to wait before stopping training if no improvement.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_path = save_path\n",
    "        self.patience = patience\n",
    "        self.best_val_loss = float(\"inf\")  # Initialize with a large value\n",
    "        self.wait = 0  # Counter for patience\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if val_loss is not None:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.model.save(self.save_path)  # Save the entire model\n",
    "                print(f\"\\nEpoch {epoch+1}: val_loss improved to {val_loss:.4f}. Model saved to {self.save_path}\")\n",
    "                self.wait = 0  # Reset patience counter\n",
    "            else:\n",
    "                self.wait += 1  # No improvement, increase patience counter\n",
    "                print(f\"\\nEpoch {epoch+1}: val_loss did not improve. Patience: {self.wait}/{self.patience}\")\n",
    "\n",
    "            # Stop training if patience limit is reached\n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"\\nEarly stopping triggered! No improvement for {self.patience} epochs.\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "# Example Usage:\n",
    "save_best_early_stop = SaveBestModelWithEarlyStopping(save_path=\"snapshots/translator_A.keras\", patience=2)\n",
    "\n",
    "# Add this when fitting your model\n",
    "# model.fit(..., callbacks=[save_best_early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 171/1563\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 69ms/step - loss: 0.8938 - masked_sparse_categorical_accuracy: 0.1501"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m model_A = tf.keras.Model(inputs=[encoder_input_layer, decoder_input_layer],\n\u001b[32m      4\u001b[39m                        outputs=[Y_proba])\n\u001b[32m      5\u001b[39m model_A.compile(loss=MaskedSparseCategoricalCrossentropy(from_logits=\u001b[38;5;28;01mFalse\u001b[39;00m), optimizer=\u001b[33m\"\u001b[39m\u001b[33mnadam\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m               metrics=[MaskedSparseCategoricalAccuracy()])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel_A\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_decoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid_decoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msave_best_early_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m ):\n\u001b[32m    219\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model_A = tf.keras.Model(inputs=[encoder_input_layer, decoder_input_layer],\n",
    "                       outputs=[Y_proba])\n",
    "model_A.compile(loss=MaskedSparseCategoricalCrossentropy(from_logits=False), optimizer=\"nadam\",\n",
    "              metrics=[MaskedSparseCategoricalAccuracy()])\n",
    "model_A.fit((X_train_encoder, X_train_decoder), Y_train, epochs=5, batch_size=64,\n",
    "          validation_data=((X_valid_encoder, X_valid_decoder), Y_valid),\n",
    "         callbacks = [save_best_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[10:11],X_train_dec[10:11],np.array(Y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pred = model_A.predict((\u001b[43mX_train\u001b[49m[\u001b[32m10\u001b[39m:\u001b[32m11\u001b[39m],X_train_dec[\u001b[32m10\u001b[39m:\u001b[32m11\u001b[39m]))[\u001b[32m0\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(pred.shape)\n\u001b[32m      3\u001b[39m y_indices = np.argmax(pred,axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "pred = model_A.predict((X_train[10:11],X_train_dec[10:11]))[0]\n",
    "print(pred.shape)\n",
    "y_indices = np.argmax(pred,axis=1)\n",
    "[text_vec_layer_es.get_vocabulary()[i] for i in y_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_vec_layer_es' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m [\u001b[43mtext_vec_layer_es\u001b[49m.get_vocabulary()[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m Y_train[\u001b[32m10\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'text_vec_layer_es' is not defined"
     ]
    }
   ],
   "source": [
    "[text_vec_layer_es.get_vocabulary()[i] for i in Y_train[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000, 50), dtype=int64, numpy=\n",
       "array([[6360,  111,    6, ...,    0,    0,    0],\n",
       "       [   7,   40,   33, ...,    0,    0,    0],\n",
       "       [  14, 1357,   24, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  17,  717,    4, ...,    0,    0,    0],\n",
       "       [  20,   15,   17, ...,    0,    0,    0],\n",
       "       [  21, 9812,    4, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[3, 3, 3, 1, 2, 1, 3, 2, 2, 1]])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.categorical([[0.01,0.01,0.01,0.97]], num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(a_model, sentence_en, temperature = 3):\n",
    "    translation = \"\"\n",
    "    for word_idx in range(max_length):\n",
    "        X =  tf.convert_to_tensor([sentence_en])  # encoder input \n",
    "        X_dec = tf.convert_to_tensor([\"starttoken \" + translation])\n",
    "        y_proba = a_model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
    "        y_proba = np.log(y_proba) / temperature\n",
    "        predicted_word_id = tf.random.categorical([y_proba], num_samples=1)[0,0]\n",
    "        print(predicted_word_id)\n",
    "        predicted_word = layer_spanish_vectorization.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == \"endtoken\":\n",
    "            break\n",
    "        translation += \" \" + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "tf.Tensor(47, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(8053, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(21, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(744, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(167, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(93, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(13, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(210, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(955, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tengo publicado los deberes así dinero un a otro piso'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model_B, \"I like soccer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! However, the model struggles with longer sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(852, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(755, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(8399, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(419, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(207, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(1448, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(87, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(717, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(1788, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(6402, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(2306, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(338, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(1442, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(8445, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(4349, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(253, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(8769, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(4673, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(577, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(826, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(3987, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(130, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(7251, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(9499, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(8153, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(4057, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(1524, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(276, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(6730, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(2634, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(333, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(163, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(4109, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(13, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(8520, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(337, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(328, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(8092, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(3996, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hablo final indicaciones edad les billetera creo acabo harías lanza esfuerzos entre encantan griego colón japón convirtieron visitarte van huevos pacientes hizo intente rendimiento pecas empeorar fácilmente cerca que cables asesinado viene coche atrapados un evacuar mayor temprano preguntémosle médica'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model_A, \"I like soccer and also going to the beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(7053, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(8191, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(4095, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(9982, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "tf.Tensor(1790, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(8097, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(4001, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(213, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(2303, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(1239, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(6682, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(750, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(52, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(764, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(2398, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(346, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(6846, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(2750, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(6506, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(2410, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(3384, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(7395, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(3299, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(181, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(7117, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(3021, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(1016, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(470, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(4243, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(147, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(533, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(1302, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(470, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(9354, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "tf.Tensor(5258, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(1162, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "tf.Tensor(6487, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(2391, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'preguntaron opuso ciertas llegasteis la estómago preciada modales desde extranjera conocía competente pasada hacer opinión actuar última vigilado respirar especiales seriamente aparentemente [UNK] enviarme logro pasado de ordinario observando campo dólares movió perro realidad profesora dólares sobredosis instalar adelante extraterrestres colectivo'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model_A, \"When I fell before the game I broke my leg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a bidirectional recurrent layer, just wrap a regular recurrent layer in a `Bidirectional` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "\n",
    "# Use a Lambda layer to handle the concatenation\n",
    "def concatenate_states(states):\n",
    "    short_term = tf.concat(states[::2], axis=-1)  # short-term (0 & 2)\n",
    "    long_term = tf.concat(states[1::2], axis=-1)   # long-term (1 & 3)\n",
    "    return [short_term, long_term]\n",
    "\n",
    "# Apply the Lambda layer to the encoder state\n",
    "encoder_state = Lambda(concatenate_states)(encoder_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the following cell will take a while to run (possibly a couple hours if you are not using a GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.6867 - masked_sparse_categorical_accuracy: 0.2579\n",
      "Epoch 1: val_loss improved to 0.4450. Model saved to snapshots/translator_B.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - loss: 0.6866 - masked_sparse_categorical_accuracy: 0.2579 - val_loss: 0.4450 - val_masked_sparse_categorical_accuracy: 0.4262\n",
      "Epoch 2/6\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3947 - masked_sparse_categorical_accuracy: 0.4653\n",
      "Epoch 2: val_loss improved to 0.3345. Model saved to snapshots/translator_B.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 95ms/step - loss: 0.3947 - masked_sparse_categorical_accuracy: 0.4653 - val_loss: 0.3345 - val_masked_sparse_categorical_accuracy: 0.5280\n",
      "Epoch 3/6\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2746 - masked_sparse_categorical_accuracy: 0.5761\n",
      "Epoch 3: val_loss improved to 0.2828. Model saved to snapshots/translator_B.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - loss: 0.2746 - masked_sparse_categorical_accuracy: 0.5761 - val_loss: 0.2828 - val_masked_sparse_categorical_accuracy: 0.5795\n",
      "Epoch 4/6\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2030 - masked_sparse_categorical_accuracy: 0.6526\n",
      "Epoch 4: val_loss improved to 0.2582. Model saved to snapshots/translator_B.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 57ms/step - loss: 0.2030 - masked_sparse_categorical_accuracy: 0.6526 - val_loss: 0.2582 - val_masked_sparse_categorical_accuracy: 0.6058\n",
      "Epoch 5/6\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1590 - masked_sparse_categorical_accuracy: 0.7084\n",
      "Epoch 5: val_loss improved to 0.2468. Model saved to snapshots/translator_B.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 60ms/step - loss: 0.1590 - masked_sparse_categorical_accuracy: 0.7084 - val_loss: 0.2468 - val_masked_sparse_categorical_accuracy: 0.6202\n",
      "Epoch 6/6\n",
      "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1297 - masked_sparse_categorical_accuracy: 0.7518\n",
      "Epoch 6: val_loss improved to 0.2443. Model saved to snapshots/translator_B.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 63ms/step - loss: 0.1297 - masked_sparse_categorical_accuracy: 0.7518 - val_loss: 0.2443 - val_masked_sparse_categorical_accuracy: 0.6281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7afd9b5d53a0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code — completes the model and trains it\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)\n",
    "save_best_early_stop = SaveBestModelWithEarlyStopping(save_path=\"snapshots/translator_B.keras\", patience=2)\n",
    "\n",
    "model_B = tf.keras.Model(inputs=[encoder_input_layer, decoder_input_layer],\n",
    "                       outputs=[Y_proba])\n",
    "model_B.compile(loss=MaskedSparseCategoricalCrossentropy(from_logits=False), optimizer=\"nadam\",\n",
    "              metrics=[MaskedSparseCategoricalAccuracy()])\n",
    "model_B.fit((X_train_encoder, X_train_decoder), Y_train, epochs=6, batch_size=64,\n",
    "          validation_data=((X_valid_encoder, X_valid_decoder), Y_valid),\n",
    "           callbacks = [save_best_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta el fútbol'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model_B, \"I like soccer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta el fútbol y no fui a la playa'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model_B, \"I like soccer and also going to the beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuando me [UNK] el domingo me rasguñó la pierna'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model_B, \"When I fell on the football field I broke my leg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'podemos vernos pero no es más importante'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model_B, \"We can order dinner but I don't want pizza.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very basic implementation of beam search. I tried to make it readable and understandable, but it's definitely not optimized for speed! The function first uses the model to find the top _k_ words to start the translations (where _k_ is the beam width). For each of the top _k_ translations, it evaluates the conditional probabilities of all possible words it could add to that translation. These extended translations and their probabilities are added to the list of candidates. Once we've gone through all top _k_ translations and all words that could complete them, we keep only the top _k_ candidates with the highest probability, and we iterate over and over until they all finish with an EOS token. The top translation is then returned (after removing its EOS token).\n",
    "\n",
    "* Note: If p(S) is the probability of sentence S, and p(W|S) is the conditional probability of the word W given that the translation starts with S, then the probability of the sentence S' = concat(S, W) is p(S') = p(S) * p(W|S). As we add more words, the probability gets smaller and smaller. To avoid the risk of it getting too small, which could cause floating point precision errors, the function keeps track of log probabilities instead of probabilities: recall that log(a\\*b) = log(a) + log(b), therefore log(p(S')) = log(p(S)) + log(p(W|S))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – a basic implementation of beam search\n",
    "\n",
    "def beam_search(a_model, sentence_en, beam_width, verbose=False):\n",
    "    X = tf.convert_to_tensor([sentence_en])  # encoder input\n",
    "    X_dec = tf.convert_to_tensor([\"startofseq\"])  # decoder input\n",
    "    y_proba = a_model.predict((X, X_dec))[0, 0]  # first token's probas\n",
    "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
    "    top_translations = [  # list of best (log_proba, translation)\n",
    "        (np.log(word_proba), layer_spanish_vectorization.get_vocabulary()[word_id])\n",
    "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
    "    ]\n",
    "    \n",
    "    # extra code – displays the top first words in verbose mode\n",
    "    if verbose:\n",
    "        print(\"Top first words:\", top_translations)\n",
    "\n",
    "    for idx in range(1, max_length):\n",
    "        candidates = []\n",
    "        for log_proba, translation in top_translations:\n",
    "            print(\".\")\n",
    "            print(translation)\n",
    "            if translation.endswith(\"endofseq\"):\n",
    "                candidates.append((log_proba, translation))\n",
    "                continue  # translation is finished, so don't try to extend it\n",
    "            X = tf.convert_to_tensor([sentence_en])  # encoder input\n",
    "            X_dec = tf.convert_to_tensor([\"startofseq \" + translation])  # decoder input\n",
    "            y_proba = a_model.predict((X, X_dec))[0, idx]  # last token's proba\n",
    "            for word_id, word_proba in enumerate(y_proba):\n",
    "                word = layer_spanish_vectorization.get_vocabulary()[word_id]\n",
    "                candidates.append((log_proba + np.log(word_proba),\n",
    "                                   f\"{translation} {word}\"))\n",
    "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
    "\n",
    "        # extra code – displays the top translation so far in verbose mode\n",
    "        if verbose:\n",
    "            print(\"Top translations so far:\", top_translations)\n",
    "\n",
    "        if all([tr.endswith(\"endofseq\") for _, tr in top_translations]):\n",
    "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(89, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(4944, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(676, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(2697, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(31, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(1405, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(2678, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(2325, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "tf.Tensor(39, shape=(), dtype=int64)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a ahora consume treinta electrónico y crimen lento adora eso'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how the model making an error\n",
    "\n",
    "sentence_en = \"I like sleeping and steak\"\n",
    "translate(model_B, sentence_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Top first words: [(-0.34797168, 'me'), (-1.6177223, 'a'), (-3.414055, 'yo')]\n",
      ".\n",
      "me\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      ".\n",
      "a\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      ".\n",
      "yo\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Top translations so far: [(-0.38936737, 'me gusta'), (-2.0557368, 'a mí'), (-3.6431463, 'yo me')]\n",
      ".\n",
      "me gusta\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      ".\n",
      "a mí\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      ".\n",
      "yo me\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Top translations so far: [(-1.7894331, 'me gusta beber'), (-2.068506, 'me gusta dormir'), (-2.0925288, 'a mí me')]\n",
      ".\n",
      "me gusta beber\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# extra code – shows how beam search can help\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_width\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mbeam_search\u001b[39m\u001b[34m(a_model, sentence_en, beam_width, verbose)\u001b[39m\n\u001b[32m     27\u001b[39m     y_proba = a_model.predict((X, X_dec))[\u001b[32m0\u001b[39m, idx]  \u001b[38;5;66;03m# last token's proba\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m word_id, word_proba \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_proba):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         word = \u001b[43mlayer_spanish_vectorization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[word_id]\n\u001b[32m     30\u001b[39m         candidates.append((log_proba + np.log(word_proba),\n\u001b[32m     31\u001b[39m                            \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranslation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m))\n\u001b[32m     32\u001b[39m top_translations = \u001b[38;5;28msorted\u001b[39m(candidates, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)[:beam_width]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/keras/src/layers/preprocessing/text_vectorization.py:451\u001b[39m, in \u001b[36mTextVectorization.get_vocabulary\u001b[39m\u001b[34m(self, include_special_tokens)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_vocabulary\u001b[39m(\u001b[38;5;28mself\u001b[39m, include_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    441\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the current vocabulary of the layer.\u001b[39;00m\n\u001b[32m    442\u001b[39m \n\u001b[32m    443\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m \u001b[33;03m            or OOV tokens.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lookup_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/keras/src/layers/preprocessing/index_lookup.py:290\u001b[39m, in \u001b[36mIndexLookup.get_vocabulary\u001b[39m\u001b[34m(self, include_special_tokens)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the current vocabulary of the layer.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m    279\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m \u001b[33;03m        any mask or OOV tokens.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# The lookup table data will not be sorted, so we will create a inverted\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# lookup here, and use that to lookup a range of indices\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# [0, vocab_size).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lookup_table.size() == \u001b[32m0\u001b[39m:\n\u001b[32m    291\u001b[39m     vocab, indices = [], []\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:321\u001b[39m, in \u001b[36m_EagerTensorBase.__bool__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m   x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np.ndarray):\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(x.size > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:385\u001b[39m, in \u001b[36m_EagerTensorBase._numpy\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> npt.ArrayLike:\n\u001b[32m    384\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# extra code – shows how beam search can help\n",
    "beam_search(model_B, sentence_en, beam_width=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct translation is in the top 3 sentences found by beam search, but it's not the first. Since we're using a small vocabulary, the \\[UNK] token is quite frequent, so you may want to penalize it (e.g., divide its probability by 2 in the beam search function): this will discourage beam search from using it too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to feed all the encoder's outputs to the `Attention` layer, so we must add `return_sequences=True` to the encoder:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
