{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0d599c-3044-43df-bebd-664dea0f66fb",
   "metadata": {},
   "source": [
    "# Linear Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f771ca1-2445-4dee-a601-cee4af1216d0",
   "metadata": {},
   "source": [
    "In class we derived the formula for linear least squares of one variable. In this notebook you will learn a bit of the numerical library numpy, use numpy to compute linear regression, and then compute it yourself using formulas from class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f580b5-4af9-41ff-98c3-49df212f6aeb",
   "metadata": {},
   "source": [
    "Begin by running the cell below. Then go back and carefully read through all the code. There is a lot of new stuff here. Note how to create numpy arrays/matrices and how to compute a linear least squares regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2d59e-a006-4638-9352-63d3f8bf099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Prepare your data\n",
    "# x: Independent variable (input)\n",
    "# y: Dependent variable (output)\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Step 2: Perform linear regression using the least squares method\n",
    "\n",
    "# Add a column of ones to the input data for the intercept (bias term)\n",
    "X = np.vstack([x, np.ones(len(x))]).T\n",
    "\n",
    "# Calculate the slope (m) and intercept (b)\n",
    "a, b = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "\n",
    "print(f\"Slope (a): {a:.4f}\")\n",
    "print(f\"Intercept (b): {b:.4f}\")\n",
    "\n",
    "# Step 3: Predict y values using the regression line\n",
    "y_pred = a * x + b\n",
    "\n",
    "# Optional: Plot the data and the regression line\n",
    "plt.scatter(x, y, color='blue', label='Data points')\n",
    "plt.plot(x, y_pred, color='red', label='Regression line')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5187f-38cf-4aba-96c7-90ff3f264611",
   "metadata": {},
   "source": [
    "## An aside about numpy matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e986b-c536-4273-b1b9-3af99704aec0",
   "metadata": {},
   "source": [
    "What happened to x? Here's the original $x$, which is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789ffd9-b199-4e2b-b449-17670e6ad230",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252ca85-950e-4d08-8c9f-05abf138f5ba",
   "metadata": {},
   "source": [
    "We add a row of 1s after it and take the transpose to get the input matrix $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948b1b1-ec50-47e1-a9b1-5d737362a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dea91d-405b-471b-9522-183049796ec8",
   "metadata": {},
   "source": [
    "Breaking this down into pieces, first let's make a python list that contains $x$ and an array of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49936e-0153-44f5-8dc9-8e7d4fece5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,np.ones(len(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee511191-9e2b-4913-b54e-78e998eeed9b",
   "metadata": {},
   "source": [
    "Now let's use numpy to make a vertical stack. The first element in the list becomes the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176d946-a689-4654-b6fd-e5191163f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack([x, np.ones(len(x))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed52a2-f587-4e48-8b48-71b71da48baa",
   "metadata": {},
   "source": [
    "And now take the transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb70f8-4b79-44ce-87e2-2aee0ce633fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack([x, np.ones(len(x))]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265d9cb-0bed-4192-a0a4-3542492bb469",
   "metadata": {},
   "source": [
    "### Practice with matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4a53e-cf82-465c-99b3-0d2a7617f2ba",
   "metadata": {},
   "source": [
    "Make a numpy matrix that is a row of 5 zeros followed by a row of 5 ones, then 5 zeros, then 5 ones again. Use built in functions and `vstack` (don't just type a bunch of 0 and 1 -- can you guess the name of a function that makes an array of zeros?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d67d5-e277-4d13-b9ca-59feb4b389bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7c950f-3dab-4d92-a04e-1d673faea38c",
   "metadata": {},
   "source": [
    "Now make a similar matrix that is a row of all 1s followed by all 2s in the second row, then 3s then 4s. Again use built in function `np.ones`. Name this matrix `M`. Hint: $[2,2,2,2,2] = 2\\cdot[1,1,1,1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a202b-e209-4ccf-95db-7f4e022076a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78050996-3fd7-462b-aee3-ecb9ea1ef2ff",
   "metadata": {},
   "source": [
    "compute M times M transpose and M transpose times M ($MM^T$ and $M^TM$). In `numpy` $AB$ can be computed with `A @ B` for matrices `A` and `B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517bc0d2-4c11-428d-833a-d23fa7db32fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad79b61c-155f-486b-8f19-f1e59205c99f",
   "metadata": {},
   "source": [
    "A matrix $M$ is *symmetric* if $M = M^T$. This also implies $M_{ij} = M_{ji}$ for all indices $(i,j)$. Write a python function `is_symmetric(M)` which returns `true` if and only if $M$ is symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72585269-b83a-4731-a004-7b408d3a2cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1656b121-a1a3-40ff-a760-487cc8491669",
   "metadata": {},
   "source": [
    "Test your function. Make a 5 by 5 random integer matrix (see `np.random.randint`) called $M$. It is a fact that $MM^T$ is always symmetric. Check that your function return `true` for $MM^T$ and `false` for $M$. Repeat this trial 100 times and verify all 100 are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837528e-7ee2-42f1-aff2-0d1d9ecacbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd47cc7d-9dfb-4884-97dc-ba7542ec8ca2",
   "metadata": {},
   "source": [
    "## Linear Least Squares Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d4e9f-570b-4e8c-afae-b60708db3191",
   "metadata": {},
   "source": [
    "You can create a vector of normally distributed samples with mean $\\mu$ and standard deviation $\\sigma$ by using the numpy function `np.random.normal(mu, sigma, n)`. Try creating a vector with 10 random samples, with a mean of 100 and a standard deviation of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb096eb-72a9-4a85-ac84-9747b632a1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43774f54-6ad7-426c-bda8-33ebd300e353",
   "metadata": {},
   "source": [
    "Now create some data for linear regression. Make a vector $x$ of ints over the range $[0,9]$ and let $y$ be a linear function of $x$, $y = 3x+2+\\epsilon(x)$ where $\\epsilon(x)$ is a random Gaussian noise function $\\epsilon(x) \\sim N(0,1)$. Make a scatter plot of $y$ vs. $x$ and label it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9473abe-d454-40dd-9a32-fac0dca303e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f8ea7e-b876-459a-8eae-b6fb25058856",
   "metadata": {},
   "source": [
    "Compute the correct linear regression coefficients using numpy as above. Check they are resonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267219b-2a14-45d5-9f25-1e3de2932468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880f37cc-748d-4e90-9555-f678b5101eb6",
   "metadata": {},
   "source": [
    "Now compute the regression coefficients using the formulas from class. Begin by defining some very helpful variables: `Sx, Sy` will be $\\sum_i {x_i}$ and $\\sum_i {y_i}$ respectively. Next `Sxx` and `Syy` are the sum of squares: $\\sum_i {x_i}^2$ and $\\sum_i {y_i}^2$. Finally the inner product `Sxy` = $\\sum_i x_iy_i$. The quickest way to do this involves using comprehensions and the `sum` function, but you can use loops for now if you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0ec6e-c37e-4c72-be01-a208cb3383b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36667f53-ab1d-4f78-b141-45f2544e63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print your results\n",
    "Sx, Sy, Sxx, Syy, Sxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31a4bf-1b76-4c86-9908-240a8c0f7695",
   "metadata": {},
   "source": [
    "Finally determine $a,b$ as in class. Display the absolute errors between your calculations and the ones numpy returned. (They should be close to machine precision, which is $10^{-15}$ give or take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d66864-a956-494c-ae1c-df5885f67111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2c2cebf-0f1a-4640-b211-9d2077275a3c",
   "metadata": {},
   "source": [
    "## Least squares function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff4d95-8ad3-483c-8e0e-c89b1f30f144",
   "metadata": {},
   "source": [
    "Did you know python can return two values? Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e12f8-8352-4e2a-ab01-3de41effe597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_numbers():\n",
    "    a = 1\n",
    "    b = 10\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ff0ab-fb6a-40af-aabf-e4ecb3c2c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = two_numbers()\n",
    "print(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d83a1-a24f-45ae-83a4-af13ba1411b3",
   "metadata": {},
   "source": [
    "Write a function `linear_least_squares(x,y)` which takes input vectors x,y and returns a,b as above. ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f01f1-bcc8-485d-af44-85b68253bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_least_squares(x,y):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa4d14-04fd-42a4-af45-974ae21836ed",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92879c6-0feb-4a49-8d70-2198e5d7cf2b",
   "metadata": {},
   "source": [
    "Now, using $a=5, b =-15$, run linear least squares 100 times on 100 vector pairs $(x,y)$, where each of the 100 $x$ are the same but the $y=ax+b+\\epsilon$ each have different amounts of Gaussian noise.  Plot the resulting best fit lines all on the same graph.\n",
    "- Use `np.arange` to make your input vector $x$ cover the domain $[-5,5]$ with a step-size of 0.01\n",
    "- Create arrays to store all the computed a and b values (you'll use this later)\n",
    "- If you call `plt.plot()` in a loop, it will keep adding to the same plot\n",
    "- Give your plot a title!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0bbb2-65f0-4e4d-b2ef-b8515bfc1e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "241ebc6d-9b71-49f1-833e-a6a131fd9f4b",
   "metadata": {},
   "source": [
    "Determine the average of the $a$s and $b$s returned above. Compare these to the true $a,b$. Explain your result.(There is an `np.mean` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ff7c5-43db-43d4-a01a-58ab80f1b173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b843037-ae51-423f-a97d-4814f409d826",
   "metadata": {},
   "source": [
    "Make two histogram plots of the calculated $a$ and $b$ values `plt.hist` works nicely and adding a semicolon suppressed the nasty text output (you'll see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a2009-f251-44e0-8942-44338d88d840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
