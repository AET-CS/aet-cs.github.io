{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5648bfa7-470a-451e-8f7c-98d9191ad526",
   "metadata": {},
   "source": [
    "# Perceptron learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e138ec5f-ba0d-46b8-b985-72a12bc55158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615818a-c57f-4ddc-abe9-6c43a436c97f",
   "metadata": {},
   "source": [
    "Perceptron learning is an iterative algorithm that converges to the appropriate weights for a single perceptron, given a learnable training set. If the training set is not learnable, the algorithm will not converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67fb04-a352-4982-89a8-c34705739dd5",
   "metadata": {},
   "source": [
    "**Perceptron Learning Algorithm**\n",
    "\n",
    "Given a dataset $X$ of $m$ observations $x \\in \\mathcal{R}^{1 \\times n}$, an outcome vector $y \\in \\mathcal{R}^{m \\times 1}$, we wish to find a weight vector $w \\in \\mathcal{R}^{n \\times 1}$ such that $y_i = A(\\mathbf{x}_i \\cdot \\mathbf{w})$ for each $0 \\leq i < m$. In matrix form: $A(\\mathbf{X} \\mathbf{w}) = \\mathbf{y}$. The last element of each observation vector $\\mathbf{x}$ will be -1 to account for the bias term.\n",
    "\n",
    "1. Initialize $ \\mathbf{w} $ as a random vector.\n",
    "2. **For each epoch**:\n",
    "    - For each $ (\\mathbf{x}_i, y_i)$ in the training set:\n",
    "      - Compute $ \\hat{y} = A(\\mathbf{x}_i \\cdot \\mathbf{w}) $.\n",
    "      - Update $ \\mathbf{w} $ as:\n",
    "        $$\n",
    "        \\mathbf{w} \\leftarrow \\mathbf{w} + (y_i - \\hat{y}) \\lambda \\mathbf{x}_i\n",
    "        $$\n",
    "3. Compute accuracy:\n",
    "   $$\n",
    "   \\text{accuracy} = 1 - \\frac{\\sum_i |y_i - A(\\mathbf{x}_i \\cdot \\mathbf{w})|}{\\text{len}(\\text{training\\_set})}\n",
    "   $$\n",
    "4. Return $ (\\mathbf{w}, \\text{accuracy}) $.\n",
    "\n",
    "The learning rate $\\lambda$ determines the rate of convergence. In practice $\\lambda$ can be close to, but not greater than, 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3e9ea-87f9-4b22-97df-b54918996b18",
   "metadata": {},
   "source": [
    "We'll define the data set as a matrix $X$ and a vector $y$ using numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1450bbf4-1e27-4d96-9de7-18e62c6c7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset corresponding to boolean AND.\n",
    "\n",
    "X = np.array([\n",
    "    [0, 0, -1],\n",
    "    [0, 1, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 1, -1]\n",
    "])\n",
    "y = np.array([[0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0c13c656-6e0e-400f-8e72-bf4fa1207425",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The heaviside step function\n",
    "\n",
    "def A(x):\n",
    "    return np.heaviside(x,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1358b-87a6-4011-9bf8-356cf2cb05ed",
   "metadata": {},
   "source": [
    "In numpy and tensorflow you will find extracting data elements with the appropriate dimensionality can be difficult. To get to i_th row of $X$, use the syntax\n",
    "\n",
    "`x = X[i:i+1]`\n",
    "\n",
    "this will ensure `x` is a matrix and not a vector (shape will be 2D not 1D)\n",
    "\n",
    "You can now multiply `x` and `w` with `x @ w`\n",
    "\n",
    "If you want `x` to be a 1D vector, you can use `x = X[i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ab507d-25dd-42ba-a5b5-e83f37d8e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_learn(X,y,lr):\n",
    "    \"\"\"\n",
    "    X = matrix of observations\n",
    "    y = vector of outcomes (as a numpy matrix)\n",
    "    lr = 0 < learning rate < 1\n",
    "    returns (weight vector, accuracy)\n",
    "    \"\"\"\n",
    "    # implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d5a54-0911-4650-8796-1366547b4099",
   "metadata": {},
   "source": [
    "**Assignment**: Determine the appropriate weight vector $w$ for the boolean function AND. Then check all 16 boolean functions on 2 variables and print weights for each *learnable* function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82a2d5-0301-478b-8626-2abb9e435ab6",
   "metadata": {},
   "source": [
    "*Sub-assignment*: You may want to write a function to generate the dataset for the i_th boolean function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
