{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55598bff-64b3-453c-8acf-79a3348aa90f",
   "metadata": {},
   "source": [
    "# Hobo Data, Student Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78da4e8-b4a2-4dc6-8794-ac1c3da0ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn as sk\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482c74a",
   "metadata": {},
   "source": [
    "We'll have three groups working on different parts of the [HOBO data](https://sites.google.com/lcps.org/hobosensordatabase/home) (described below). \n",
    "\n",
    "* Group 1 will extract sensor coordinates from a satellite image screenshot. You will produce a funtion that returns screen cooriadte for x,y pairs as in:\n",
    "\t*  pos(\"A\",\"30\") = 143,299\n",
    "* Group two will ingest and clean the all the relevant data and store it in arrays indexed by <x,y,t> (horizontal, vertical, time, so that a user can query\n",
    "\t* \"A, 30, 01/27/2022 17:28:08\" and return the reading -0.95\t34.40\n",
    "* Group 3 will explor 3D plots in matplot lib specifically contour and surface plots, and then animate the plots as parameters change. You can start with variants of $y = e^{-x^2} \\sin(t)$ and $z =4 \\sin (t) e^{-x^2-y^2} \\cos \\left(4 x^2+4 y^2\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7d67a",
   "metadata": {},
   "source": [
    "## Part 1: Extracting Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3d304",
   "metadata": {},
   "source": [
    "There's some data being collected [here](https://sites.google.com/lcps.org/hobosensordatabase/home) Read about the hobo data first. Then identify the data for the \"red\" grid of sensors for ACL. in part 1 you will approximate the coordinates of these sensors by analyzing a screenshot. You're using the openCV library \"cv2\" which should be installed in this environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6665e441-e068-4076-a294-b32da67d4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = cv2.imread(\"red_sensor_image.png\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905fbfb",
   "metadata": {},
   "source": [
    "Find the shape and then select a submatrix that is square but doesn't cut off any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47087191-ef86-4122-8973-5eac9fb79081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180, 1235, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c4080b-f264-43b8-b4cc-1d5f64c87bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180, 1180, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic = pic[:,0:1180,:]\n",
    "pic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a094d4",
   "metadata": {},
   "source": [
    "Convert the image from BGR to RGB (openCV uses a different ordering of color data) and then display. Use the commands `cv2.cvtColor` and `plt.imshow()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11b114",
   "metadata": {},
   "source": [
    "To find the red dots, we choose to analyse just the red layer of pixel information. Split the image into RGB channels using `cv2.split` and dislay the red channel only, as grayscale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc2475",
   "metadata": {},
   "source": [
    "You see the red pixels are nearly white and the background is nearly black. We want to crush this image into 0s and 255s for black and white, so the red dots really pop. Use matplotlib filtering syntax (much like pandas filtering). Any pixel with a red above 200 should become 255. Anything below should be 0. (Be sure to **copy** your red matrix first in case you mess up.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1cb4e-a4dc-40a2-bd2b-fcdef65c2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the red matrix here as a sanity check\n",
    "# and its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fc890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cda10b3e",
   "metadata": {},
   "source": [
    "**Plot your black and white matrix here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed2d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c844578e",
   "metadata": {},
   "source": [
    "### Machine Learning -- KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e2137",
   "metadata": {},
   "source": [
    "We need to know the location of the centers of these dots, in the coordinate space of the picture. the kMeans algorithm is perfect for this. It finds local centers of clusters. I'll get you started with a list of all the pixels that have white centers. The KMeans algorithm will determine all the centers and list them for you as coorindate pairs. You should tell it how many centers you're looking for. Then create a plot with (a) the original image and (b) the centers plotted as white 'x' symbols (look at plt.scatter(marker = ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af99759-ba0d-4e2f-a393-594b0a4219fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  30,  828],\n",
       "       [  30,  829],\n",
       "       [  30,  830],\n",
       "       ...,\n",
       "       [1162,  192],\n",
       "       [1162,  193],\n",
       "       [1162,  194]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Extract the coordinates of the white pixels (where red == 255)\n",
    "white_pixels = np.column_stack(np.where(red2 == 255))\n",
    "white_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply KMeans to find the centers of the white dots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c161c1-46c2-42b9-b623-2cca2b9894bd",
   "metadata": {},
   "source": [
    "## Part 2: Ingesting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca5473-978d-4a2a-9447-27c23183b83c",
   "metadata": {},
   "source": [
    "Use pandas to read spreadsheet csv files into data frames. You will probably want to merge frames to get one big one. Then think about how to filter or aggregate the data so it's ready to go when someone asks for a location and time -- you should give it to them. (Assume their input is valid at first, but then handle the case when it isn't)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf7f3f",
   "metadata": {},
   "source": [
    "## Part 3: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a736c",
   "metadata": {},
   "source": [
    "Read up on matplotlib 3d plotting. There are four different things here\n",
    "* 3d plots and contour plots (related)\n",
    "* animation\n",
    "* animation with 3d plots\n",
    "* saving the animation as a file\n",
    "\n",
    "Thare are plenty of tutorials on saving a simple 2d animation. I'd do that first. Then play around with 3d contour and surface plots. Finally try to get an exported video of a 3d animation. (you might need ffmpeg, it's easy to install on the unix side of WSL)\n",
    "\n",
    "The goal here is to be able to take grids of data (x,y,t,z) corresponding to location and time and an output like temperature, and plot that as a 3d surface and/or contour and then animate it for a range of times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Python",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
