{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c217550-ac39-4cd8-9772-8775df1f9345",
   "metadata": {},
   "source": [
    "# Generating Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41700ae-dae2-4280-9207-2501b2857160",
   "metadata": {},
   "source": [
    "You will create a small RNN network to learn how to write Shakespeare text letter by letter. Unfortunately these types of model take a very long time to train (hours) on a decent GPU so your results today in class won't be optimal. They may still impress you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6526346-1657-45f4-9861-52937754ed4d",
   "metadata": {},
   "source": [
    "First load the dataset from the intenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8d2c0-e08e-4250-bea5-700ebb267a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download the file\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Print some info\n",
    "print(\"Downloaded Shakespeare text. Length:\", len(text), \"characters\")\n",
    "print(text[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db65b4-5766-4920-80b5-fd6bbe4365a0",
   "metadata": {},
   "source": [
    "You need to transform this into an array of integers instead of characters. Use the sklearn LabelEncoder. You should find 64 distinct characters. To be sure, print out all the encoded integers and the character they correspond to. *If you want* you can lowercase all the letters first. This may speed up training some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b6a32-a662-4f2c-834f-e5d109784b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088c6f3-0c55-43ab-a4ca-c87bdcb8c96d",
   "metadata": {},
   "source": [
    "Now as you did last class, convert this single array into X,y pairs, where each row of X is a string of characters and each y is the next character. For example\n",
    "\n",
    "'to be or not to b', 'e'\n",
    "'what light throug', 'h'\n",
    "\n",
    "You can choose how long you want the string of X chars to be (64,128,256 -- something in this range is reasonable. Smaller is faster to train. Longer makes a smarter model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f5dc8-de9d-4920-b72c-d5b311acbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6612a-d8c8-4c26-8bfa-881402cf1c1b",
   "metadata": {},
   "source": [
    "Create a train/test set by choosing the first say 80% of the data for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48f791-c5e3-4eb1-bec8-8c9563cfe64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e32270-a155-46c1-9fed-6f70a0f4262f",
   "metadata": {},
   "source": [
    "Input to an RNN needs to be a 3D tensor. You will probably need to reshape your data.\n",
    "\n",
    "```python\n",
    "# Reshape the input data for LSTM (samples, timesteps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "```\n",
    "\n",
    "For example if X_train.shape is (1000,100,1) then you have 1000 phrases each of length 100. The '1' wraps this in a 3D tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c40cf-c090-41f5-a5e0-88d059f766cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782aee1a-eb6b-482a-871d-a36ded7eef4e",
   "metadata": {},
   "source": [
    "Define your RNN. Use one layer of RNN -- you can choose SimpleRNN, LSTM, or GRU with similar semantics. Here is an outline\n",
    "\n",
    "```python\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Input([None,1])\n",
    "model.add(GRU(128)) # 128 hidden units in one GRU layer\n",
    "model.add(Dense(alphabet_size, activation='softmax'))\n",
    "```\n",
    "\n",
    "The input is a sequence of *any length* (hence the `None`), but only 1D (characters). The output is a 1-hot encoded vectors over each character. Train this using cross entropy and adam optimizer. You can pick any batch size (larger is faster, consult the GPU memory usage). Don't expect super high accuracy, train only for a few epochs (10 or less, maybe much less! Start with 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce09d31-8331-4f2a-9070-eeea05c652b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7c5aa-89ae-482f-89a8-f64ce70577d5",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a090ad16-bbd1-42aa-a359-afe60c3162a3",
   "metadata": {},
   "source": [
    "This is a bit trickier than what we've done before. You need to process an input phrase, convert it to an array of ints, feed it to the model, get the logits of output, define a probability distribution,\n",
    "select an element according to that distribution, append the result to the input, and then do this over in a loop until you have generated as much output as you want. We can break this down into pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ba04a-3717-4a0e-879e-c8e49c8faff7",
   "metadata": {},
   "source": [
    "First write `next_char(text, temp)` that gets the single next character predicted using `text` as input. Remember to employ the temperature. Here's a snippet that may help\n",
    "\n",
    "```python\n",
    "  probs = # output from your model\n",
    "  logits = np.log(probs)/temp # we have to invert the softmax to get back to logits, then divide by temp\n",
    "  char_id = tf.random.categorical(logits, num_samples=1) # helper function to apply softmax and then randomly sample\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c720a-f149-4a07-b06f-b4c4ca55de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e318e-216a-4bc4-80c2-1568dbc2042e",
   "metadata": {},
   "source": [
    "Now write `extend_text(text, n_chars, temp)` to add any number of characters to `text` by calling `next_char` repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8ba3c-856d-4a5f-9443-7d3ad33ac6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb3f6c1-cc25-4e69-87bb-b9394b78d789",
   "metadata": {},
   "source": [
    "Finally, generate some Shakespeare! Experiment with different seeds and seed lengths and temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d62982-3067-48c6-b244-b2118b2f8aa1",
   "metadata": {},
   "source": [
    "## Saving State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d436c-e180-4de6-855b-1c6518c92523",
   "metadata": {},
   "source": [
    "When training gets this involved you really need some good practices to save your work. Here's a callback that saves progress as you train. Especially important this is on Colab, which will stop and shutdown your session if you don't make it feel special all the time.\n",
    "\n",
    "```python\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath = 'best_shakespeare_model.keras'\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,  # Save the entire model\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    mode='min',  # Save the model when val_loss is minimized\n",
    "    save_best_only=True  # Only save the best model\n",
    ")\n",
    "\n",
    "# Train the model with the callback\n",
    "history = model.fit(X_train, y_train, epochs=500,  validation_split=0.1, callbacks=[model_checkpoint_callback])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7f414-1ace-40b1-b842-289d2cdea7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
