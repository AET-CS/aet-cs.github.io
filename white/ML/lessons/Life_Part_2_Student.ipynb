{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95728b0f-8f3f-489c-8a07-92096519388c",
   "metadata": {},
   "source": [
    "# Life Expectancy -- Normalization, Regularization, Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05f467-fca2-446a-99a3-050e2aed45b6",
   "metadata": {},
   "source": [
    "Last class we created a linear model for the WHO life expectancy database. Today we will focus on various ways to interpret the model and refine it, specifically by interpreting the importance of each model feature and selecting a subset of features that make our model more interpretable and more extensible.\n",
    "\n",
    "Outline\n",
    "\n",
    "1. Linear regression coefficients\n",
    "2. Normalizing the inputs\n",
    "3. Ridge Regression (L2)\n",
    "4. Lasso Regression (L1)\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316872c-6b65-499b-ac9f-6240b45722a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed64ed8-a168-4479-ac47-678d17e46b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec9f9f6-91d9-4fcc-b32a-a74b490ff45d",
   "metadata": {},
   "source": [
    "Let's copy our code to load and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ca67d-b28b-41aa-96b9-35562b083cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines would load the data locally\n",
    "data_root = \"./\"\n",
    "filename = \"Life_Expectancy_Data.csv\"\n",
    "filepath = os.path.join(data_root, filename)\n",
    "\n",
    "# We'll fetch it directly from the web\n",
    "# data_url = \"https://aet-cs.github.io/white/ML/lessons/Life_Expectancy_Data.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "target = \"Life expectancy\"    \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150c8c9-0b3b-4be5-bc7c-185fef576f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ae59d-1b5a-43ff-a0c0-234593e01f5e",
   "metadata": {},
   "source": [
    "For today's exercise we will return to an ordinal encoding of the country feature. From last class it was obvious that counry has a tremendous impact on life expectancy. But we're interested in more general relationships. We want to see what can be said without relying on knowledge of the country. So our preprocessing method will comment out the 'get_dummies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044b04b-52cd-4a25-864f-9e626dc8181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(df, one_hot_encode = False):\n",
    "    target = \"Life expectancy\"    \n",
    "\n",
    "    # Use sklearn Imputers to fill in the categorical and numerical columns\n",
    "    simple_median = SimpleImputer(strategy='median')\n",
    "    simple_most_freq = SimpleImputer(strategy='most_frequent')\n",
    "    \n",
    "    num_cols = df.select_dtypes(include=np.number).columns # numerical data\n",
    "    cat_cols = df.select_dtypes(include=object).columns # categorical data\n",
    "\n",
    "    df[num_cols] = simple_median.fit_transform(df[num_cols])\n",
    "    df[cat_cols] = simple_most_freq.fit_transform(df[cat_cols])\n",
    "    \n",
    "    if one_hot_encode:\n",
    "        O_encoder = OrdinalEncoder()\n",
    "        df[cat_cols]= O_encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "        # df = pd.get_dummies(df, dtype=int)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e831cd5-d5dc-4519-846a-9739fd3988aa",
   "metadata": {},
   "source": [
    "We add a method here to drop features. We will only use this sometimes, so it is not a part of \"pre_process_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19601e-85e9-4a59-9bbc-b2079a62f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    df = df.drop([\"under-five deaths\", \"Diphtheria\", \"thinness 1-19 years\", \"Polio\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209f513-1697-49e6-a0d5-e18475c9f372",
   "metadata": {},
   "source": [
    "The random_state logic here is a bit different. We want randomized training set selection as the default so unless the caller sets `random_state=true`, we return a different training_set each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139346aa-ee6a-4510-bff9-74d0d1ca352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train(df, test_size = 0.2, random_state = False):\n",
    "    target = \"Life expectancy\"    \n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    if random_state:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size, random_state=42)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289e3dc-91c6-485d-9ab4-6dfaafb1b1ce",
   "metadata": {},
   "source": [
    "## First Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc022c34-66bb-4e72-b5a1-8d92fdf9e383",
   "metadata": {},
   "source": [
    "Let's do a vanilla linear regression and check the results. Notice the use of `model.score` to get an $r^2$ score. Each model has a different `score` method (usually $r^2$ for regression). Also note the use of python \"f-string\" which interpolate variable values into strings. There is also a format specifier in this case indicating 3 decimal places to be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7e910-36c6-420c-9efe-fc77cd5a65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(filename)\n",
    "df = pre_process_data(df, one_hot_encode = True)\n",
    "X_train, X_test, y_train, y_test = get_test_train(df)\n",
    "lreg = LinearRegression()\n",
    "model = lreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21e05e-c30f-40f7-a046-99052c3f85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lreg.predict(X_test)\n",
    "print(f\"Train R-squared  = {model.score(X_train, y_train):.3}\")\n",
    "print(f\"Test  R-squared  = {model.score(X_test, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b199fac-e894-4bf5-8c4d-0c0866ed5360",
   "metadata": {},
   "source": [
    "Because of the random state, the previous two cells will return slightly different results each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0243c-8de0-46fd-83d9-e10d7ff9c700",
   "metadata": {},
   "source": [
    "Let's plot the coefficients. Note how the `model` object contains the coefficients. The underscore \"_\" in the variable name is a convention in Python that communicates the idea of a \"Java private\" field, except it's not private. This is an internal field that you should *not* mess with unless you know what you're doing. But you can read it all day long without fear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e3b8d-55fd-4746-a654-ab0c1631f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(y = df.drop(target,axis=1).columns, width=model.coef_);\n",
    "plt.title(\"Linear Regression Coefficients\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d4d1c-32e7-4630-8ce2-db5cdf93ca83",
   "metadata": {},
   "source": [
    "Look closely at this graph. We discussed how the coefficient here is a measure of importance. If, for example, `HIV/AIDS` increases by one unit, then the life expectancy should decrease by about 0.5 units. Of course the units vary from feature to feature. So comparing these coefficients directly is basically impossible. We'll fix this in the next section.\n",
    "\n",
    "But first, let's get a sense of the *stability* of our model. Each time we get a train/test split, it gives us a different $r^2$ value. If we repeat the selection and fit process 50 times, the range of values gives us a sense of the model's stability and also a better assessment of our real score. Write some code that\n",
    "\n",
    "1. Runs a linear model 50 times (start from scratch: `df = get_data(filename)` to be safe\n",
    "2. Collects the scores on the *test data*\n",
    "3. Makes a scatter plot of the scores, with a title\n",
    "4. Prints the mean and stdev of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1bc9e7-d798-43b2-815c-301592dbc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7da53a-9666-4bff-84df-e17a57480cb4",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629572a-ab3b-4a21-9d5f-c5dc994e1d88",
   "metadata": {},
   "source": [
    "The data has come to us in vastly different scales. Population can be in the billions, and percent expendature is close to 1. A standard best practice is to scale your input features before modeling. In this case we transform each feature $x_i$ by\n",
    "\n",
    "$$x_i \\leftarrow \\dfrac{x_i - \\mu_i}{\\sigma_i}$$\n",
    "\n",
    "which sets the mean to 0 and the new standard deviation to 1. \n",
    "\n",
    "To simplify things, we'll just redefine `get_test_train`. (We could scale the features earlier in preprocessing, but sklearn returns a matrix here, not a dataframe. So we would have to reconstitute the dataframe after scaling. This way is simpler and works for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cfd2d-f971-452b-b224-b57dc4e1ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train(df, test_size = 0.2, random_state = False):\n",
    "    target = \"Life expectancy\"    \n",
    "    X = df.drop(target, axis=1)\n",
    "\n",
    "    # add a scaler here. It works by finding a fit first (computing mu and sigma)\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    # and then transforming the data\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    y = df[target]\n",
    "    if random_state:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size, random_state=42)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff98d74-f578-4066-adfc-0ff534eb274f",
   "metadata": {},
   "source": [
    "Copy and modify the code before to make a scatter plot of the scores of 50 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1923f-db57-437d-84f1-d0d0c90c33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de38b3-c880-4ace-8744-be6c1536c7e6",
   "metadata": {},
   "source": [
    "And also plot the regression coefficients, as before. Also print the \"schooing\" coefficient, which is the last entry in the `coef_` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa354b5f-acba-4233-8d25-3960e6d9896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33128a-e186-423d-b9c4-665f0d31f449",
   "metadata": {},
   "source": [
    "These coefficients are now in units of (years/standard deviation). If schooling increases by about $1\\sigma = 3.3589$ years then life expectancy increases by about 2 years (we did not scale the target). Normalization definitely helps with interpretations. But there are still some weird things going on here? **Discuss**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad869abd-3706-4912-8bb0-843cbed8dd9e",
   "metadata": {},
   "source": [
    "## Eliminating Collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2fc9e-268a-491d-b285-f1768ab8f229",
   "metadata": {},
   "source": [
    "In the last lab we saw how collinear features can increase the condition number of the linear least squares regression matrix, which leads to possibly unstable solutions. It also interferes with the interpretability of regression coefficients. If 2 features are already related (e.g. $x_1 = -0.3 x_2$, then either regression coefficient can change arbitrarily as long as its paired coefficient changes in tandem. By manually dropping highly correlated features we can reduce this effect somewhat (although we can't eliminate it entirely. If you look at the correlation heatmap, there is a lot is cross-correlation in this dataset.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb86d8-8423-483f-85b9-35b6bb7cd521",
   "metadata": {},
   "source": [
    "Repeate the analysis from the last section here, but first drop collinear columns. A method has been defined for you (look above). Feel free to modify which subset of columns are dropped. You should create both\n",
    "\n",
    "1. A scatter plot of 50 regression model scores, with dropped features\n",
    "2. A Coefficients horizontal bar plot of one of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1879635a-7088-4848-8a1b-de0d8eb3dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3c634-10c9-47e7-b713-b385121d9373",
   "metadata": {},
   "source": [
    "Compare these results to the non-dropped results. **Discuss**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4215322-5283-480d-803e-729340839b1a",
   "metadata": {},
   "source": [
    "As a final analysis, it is interesting to see how the regression coefficients change as a result of the training set selection. We have been warned this model may be unstable. If this results in wildly varying regression coefficients, then we should doubt the validity of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa04553-b7c5-4f47-8420-fc5be9ea1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = []\n",
    "for a in range(200):\n",
    "    df = get_data(filename)\n",
    "    df = pre_process_data(df, one_hot_encode = True)\n",
    "    df = feature_selection(df)\n",
    "    X_train, X_test, y_train, y_test = get_test_train(df)\n",
    "    lreg = LinearRegression()\n",
    "    model = lreg.fit(X_train, y_train)\n",
    "    coefs.append(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18045a0c-1b55-47df-a65c-e37feab026af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(range(200), coefs)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Weights\")\n",
    "plt.title(\"Regression coefficients as a function of the training set\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b545f0-9f33-4fb0-adb2-07afd0003fdd",
   "metadata": {},
   "source": [
    "These weights look pretty stable to me. So I think we're OK with this regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b9a97-fcbe-4c0d-ad6d-118f974e0b73",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20322e0-2522-4e13-9e5e-fa29d87cf2d2",
   "metadata": {},
   "source": [
    "While our current linear model is relatively stable to training set fluctuations, it still exhibits a wide range of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bac187-17d7-414e-a4fd-c93b93dd7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.abs(model.coef_)\n",
    "print(f\"Ratio of largest to smallest coefficient: {np.max(c)/np.min(c): 0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a409501-13f7-43d2-898c-3d94551931bc",
   "metadata": {},
   "source": [
    "It is possible to drive these weights to be closer together by applying a regularization technique to our optimization model. We add a term to the error function that penalizes large coefficients. Normally in linear regression the error (loss) function for $m$ observations and $n$ features is\n",
    "\n",
    "$$err = \\sum_{i=1}^m (y_i - \\tilde{y}_i)^2$$\n",
    "\n",
    "We change this to\n",
    "\n",
    "$$err_{\\alpha} = \\sum_{i=1}^m (y_i - \\tilde{y}_i)^2 + \\alpha \\sum_{i = 0}^{n} a_i^2$$\n",
    "\n",
    "where the $a_i$ are the computed fit coefficients and $\\alpha$ is a tunable parameter of the model. This is called *ridge* regression ($L_2$ regularization) and is available in scikit-learn. The larger $\\alpha$ penalizes coefficients more and drives them smaller. Because of the squared term, large coefficients are penalized relatively more than small ones and will decrease at a faster rate.\n",
    "\n",
    "To see the effect of ridge regression, we run 200 trials with $\\alpha$ varying from $1$ to $10^6$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51115fd2-1cbb-43dc-9b3c-22c28d6414ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "\n",
    "# create a list from 10^6 down to 10^0, log spaced\n",
    "alphas = np.logspace(6,0, n_alphas)\n",
    "\n",
    "# run a ridge regression for each alpha\n",
    "coefs = []\n",
    "\n",
    "# We perform this on the full dataset -- NO feature selection\n",
    "df = get_data(filename)\n",
    "df = pre_process_data(df, one_hot_encode = True)\n",
    "df = feature_selection(df)\n",
    "X_train, X_test, y_train, y_test = get_test_train(df)\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha=a, fit_intercept=False)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84c08f-67cd-43ae-ba92-d1007da7afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.title(\"Ridge coefficients as a function of $\\\\alpha$ \")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2da8f-561e-4875-8500-505024a1f06f",
   "metadata": {},
   "source": [
    "We pick $\\alpha=10^3$ and interpret the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d782d8b-f606-428d-9e00-7dbfce923b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1000\n",
    "\n",
    "ridge = Ridge(alpha=alpha, fit_intercept=False)\n",
    "ridge.fit(X_train, y_train)\n",
    "plt.barh(y = df.drop(target,axis=1).columns, width=ridge.coef_);\n",
    "plt.title(\"Linear Regression Coefficients\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c1f45-bde9-4b15-a503-213654feed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.abs(ridge.coef_)\n",
    "print(f\"Ratio of largest to smallest coefficient: {np.max(c)/np.min(c): 0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c0abf-08d0-433d-b80c-5e96fd4f5446",
   "metadata": {},
   "source": [
    "The ratio hasn't decreased all that much. You should\n",
    "\n",
    "1. Experiment with different alpha values.\n",
    "2. Then, go back to the dataset and try dropping the collinear columns again.\n",
    "\n",
    "What effect does this have? **Discuss** \n",
    "\n",
    "There is a bit of art and science in regularizing data. Ridge regression may not be doing much for us. Let's try another method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea042e6-e11c-468d-8c5a-2762a850cf0b",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ddf10f-f209-453b-a142-207f5f1890ee",
   "metadata": {},
   "source": [
    "Lasso regression ($L_1$ regularization) uses the error (loss) function\n",
    "\n",
    "$$err_{\\alpha} = \\sum_{i=1}^m (y_i - \\tilde{y}_i)^2 + \\alpha \\sum_{i = 0}^{n} |a_i|$$\n",
    "\n",
    "This has the interesting mathematical effect of not just decreasing the magnitude of coefficient but actually driving coefficients to zero. The result is that the remaining features with non-zero coefficients can be interpreted as \"most important\" and lead to a simpler model with similar accuracy to a larger model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d5469-6c32-419a-95d0-337f8f9815fd",
   "metadata": {},
   "source": [
    "Lasso regression is also built into scikit-learn. Let's do a similar analysis. (This next loop may throw some warning. You can disgregard them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0deaf-96f3-4ec5-a628-503bf649b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "alphas = np.logspace(1,-2, n_alphas)\n",
    "\n",
    "coefs = []\n",
    "\n",
    "\n",
    "# We perform this on the full dataset -- NO feature selection\n",
    "df = get_data(filename)\n",
    "df = pre_process_data(df, one_hot_encode = True)\n",
    "X_train, X_test, y_train, y_test = get_test_train(df)\n",
    "\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a, fit_intercept=True)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca881f-0b35-4a9b-8d60-ba13c3b53e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.title(\"Lasso coefficients as a function of $\\\\alpha$\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3037da8-9ee2-40f3-a76e-8389830cad13",
   "metadata": {},
   "source": [
    "Based on the above graph, pick an $\\alpha$ value for your regression model in the cell below. We will see a number of the features *completely disappear* from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d4bd3-af19-46dc-ade5-1002082c3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = # your alpha here\n",
    "\n",
    "lasso = Lasso(alpha=alpha, fit_intercept=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "plt.barh(y = df.drop(target,axis=1).columns, width=lasso.coef_);\n",
    "plt.title(\"Linear Regression Coefficients\");\n",
    "print(f\"Score on test set {lasso.score(X_test, y_test):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f57106-4b08-4d26-ae1b-ab3e1e261a71",
   "metadata": {},
   "source": [
    "We can filter out the non-zero features and sort the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bdedf-2ebe-4a5c-b209-75967b829ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.array([df.drop(target,axis=1).columns, lasso.coef_]).T, columns = ['feature', 'coeff'])\n",
    "\n",
    "filtered_results = results[abs(results['coeff'])>0].sort_values(by='coeff')\n",
    "\n",
    "plt.barh(y = 'feature', width='coeff', data = filtered_results);\n",
    "plt.title(\"Lasso Regression Coefficients\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81d373-5b7c-4179-9b26-15c0f97ae813",
   "metadata": {},
   "source": [
    "This model is much smaller than the original, which means it is maybe easier to interpret. Let's see if our accuracy has diminished any?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44905d24-a436-428d-999d-365b96c88859",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(100):\n",
    "    df = get_data(filename)\n",
    "    df = pre_process_data(df, one_hot_encode = True)\n",
    "    X_train, X_test, y_train, y_test = get_test_train(df)\n",
    "    lasso = Lasso(alpha=alpha, fit_intercept=True)\n",
    "    model = lasso.fit(X_train, y_train)\n",
    "    scores += [model.score(X_test, y_test)]\n",
    "plt.scatter(x = range(len(scores)), y = scores);\n",
    "print(f\"Linear Model: Mean score = {np.mean(scores):.3} Stdev = {np.std(scores):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150de811-c0c0-45a3-871b-30d5b599a026",
   "metadata": {},
   "source": [
    "**Rerun** the last few cells with different alpha values and decide which alpha you like the best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Python",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
