{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ec9701-063f-4715-85fa-0526d0f673cc",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7337b99-a4c7-4782-a2f1-efe0bd75e470",
   "metadata": {},
   "source": [
    "A Gaussian Micture Model for the credit card fraud problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba567451-34d9-43ad-8f84-ca94c4384bb9",
   "metadata": {
    "_cell_guid": "f8910a9e-5a63-4b90-8f77-6ddaf72b3d8e",
    "_uuid": "0505c5fc2631957b110675fc7ed368068d945580"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict,cross_val_score, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,f1_score,recall_score,precision_score,accuracy_score,precision_recall_curve,roc_curve,roc_auc_score\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6723a2-1fdd-46c8-9dd7-1fd39fe0d961",
   "metadata": {
    "_cell_guid": "849a3e0f-02ec-4d6f-adf1-2c3c08651a41",
    "_uuid": "649f475f74125199a224e7ddf1cfa069f37f2eaf"
   },
   "outputs": [],
   "source": [
    "def Print_Accuracy_Scores(y,y_pred):\n",
    "    print(\"F1 Score: \", f1_score(y,y_pred))\n",
    "    print(\"Precision Score: \", precision_score(y,y_pred))\n",
    "    print(\"Recall Score: \", recall_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934bab23-2b7b-4a80-b2ec-6c51fe59c28f",
   "metadata": {
    "_cell_guid": "b6081bbd-cfe9-4da7-aa69-85cff0b9ced6",
    "_uuid": "23cd5a58f6c4bb5762fda6275fb4278aace0ec25"
   },
   "outputs": [],
   "source": [
    "#Loading Dataset\n",
    "# UNCOMMENT ONE\n",
    "\n",
    "url = \"https://github.com/AET-CS/aet-cs.github.io/blob/main/white/ML/data/creditcard.csv\"\n",
    "\n",
    "# cc_dataset = pd.read_csv(url=url)\n",
    "# cc_dataset = pd.read_csv(\"../data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f022b6-3207-4c27-b3ce-00294e0819aa",
   "metadata": {
    "_cell_guid": "62960c8b-bac6-4e1f-b942-6a9e5f2b7019",
    "_uuid": "80fa9da12f8a3565e842ed748284db025abf08ad"
   },
   "outputs": [],
   "source": [
    "cc_dataset.drop(labels = ['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8','Time'], axis = 1, inplace=True)\n",
    "cc_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd3ef4-103c-4379-8d2e-ebc4e197336a",
   "metadata": {
    "_cell_guid": "7981708a-547e-412a-b494-97a4d1cc130a",
    "_uuid": "9555dc9e72b84227e82c1c465c18feb98c7cd65a"
   },
   "outputs": [],
   "source": [
    "cc_dataset.drop(labels = ['V1','V2','V5','V6','V7','V21','Amount'], axis = 1, inplace=True)\n",
    "cc_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94022c-e4db-48f9-99d3-951a02288bfa",
   "metadata": {
    "_cell_guid": "a699a497-659b-44bc-a052-97f616352b70",
    "_uuid": "a172b8651df6686679d0927cc03df7ceada19431"
   },
   "outputs": [],
   "source": [
    "genuine_data = cc_dataset[cc_dataset['Class']==0]\n",
    "fraud_data = cc_dataset[cc_dataset['Class']==1]\n",
    "\n",
    "# optionally reduce data for speed\n",
    "genuine_data = genuine_data.sample(frac=1, random_state=42)\n",
    "fraud_data = fraud_data.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c5552-f005-42e7-aeb5-3eb36deced00",
   "metadata": {
    "_cell_guid": "58acf65d-82ba-4bbf-8fd9-20e3f85a99dd",
    "_uuid": "ce45cbcb894e73cdea2a27f037fee7720d5f021b"
   },
   "outputs": [],
   "source": [
    "#Split Genuine records into train & test - 60:40 ratio\n",
    "genuine_train,genuine_test = train_test_split(genuine_data,test_size=0.4,random_state=0)\n",
    "print(genuine_train.shape)\n",
    "print(genuine_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980625cc-e097-449a-9ccc-eebc28199965",
   "metadata": {
    "_cell_guid": "20ff9c27-4fb1-4c88-ae6d-081b521fe168",
    "_uuid": "aba4979878cdd5e83539368d57e4a2e163d3b563"
   },
   "outputs": [],
   "source": [
    "#Split 40% of Genuine Test records into Cross Validation & Test again (50:50 ratio)\n",
    "genuine_cv,genuine_test = train_test_split(genuine_test,test_size=0.5,random_state=0)\n",
    "print(genuine_cv.shape)\n",
    "print(genuine_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9862c-0794-400d-86db-5dc1fecf5422",
   "metadata": {
    "_cell_guid": "ff9d73c8-52f1-47de-9414-75e84d75abe9",
    "_uuid": "a2adcf3d8a0dbb59aef026475be2395aeffc92f0"
   },
   "outputs": [],
   "source": [
    "#Split Fraud records into Cross Validation & Test (50:50 ratio)\n",
    "fraud_cv,fraud_test = train_test_split(fraud_data,test_size=0.5,random_state=0)\n",
    "print(fraud_cv.shape)\n",
    "print(fraud_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b918db-409c-4e3b-a1dd-f3dc7532b309",
   "metadata": {
    "_cell_guid": "dcace0dc-3e71-4747-8b96-18838a81c278",
    "_uuid": "babb30b84f143fbb941435e67d4ded4efe011ff7"
   },
   "outputs": [],
   "source": [
    "#Drop Y-label from Train data\n",
    "train_data = genuine_train.drop(labels='Class',axis=1)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43a5b1-259a-4d95-ae8a-78eb8c7cb876",
   "metadata": {
    "_cell_guid": "5d0ecfd6-7770-437b-a0d0-5aab32dd81df",
    "_uuid": "352be0e31383211334638e5ca601d506db9bea58"
   },
   "outputs": [],
   "source": [
    "#Cross validation data\n",
    "cv_data = pd.concat([genuine_cv,fraud_cv])\n",
    "cv_data_y = cv_data['Class']\n",
    "cv_data.drop(labels='Class',axis=1,inplace=True)\n",
    "print(cv_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07aef12-2513-412e-a779-730da749739d",
   "metadata": {
    "_cell_guid": "c0861bef-45a6-46cc-bd5f-d34e3ddd00ff",
    "_uuid": "ad9ebd1b452f23325d87d82fec4d123a3532a110"
   },
   "outputs": [],
   "source": [
    "#Test data\n",
    "test_data = pd.concat([genuine_test,fraud_test])\n",
    "test_data_y = test_data['Class']\n",
    "test_data.drop(labels='Class',axis=1,inplace=True)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4eb35b-d250-41f6-a12d-9af630d1a5d1",
   "metadata": {},
   "source": [
    "## The GMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e2a57-a598-4ad6-a19d-520fc48e3aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "# Fit GMM to data (assuming 'data' contains normal instances)\n",
    "gmm = GaussianMixture(n_components=1, covariance_type='full', random_state=0)\n",
    "gmm.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72fff4-bda9-4399-bb64-643bbdcf0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the log probability np.of each point\n",
    "log_probs = gmm.score_samples(train_data)\n",
    "sns.distplot(log_probs,color='r',label='Valid Class');\n",
    "plt.title(\"Log probabilities of training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b9135-2163-4d6f-a432-2f506f02e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(log_probs), np.min(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03c8fe-1f23-4b70-844a-d3bbfa2dd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Compute log-likelihoods for validation data\n",
    "log_probs_cv = gmm.score_samples(cv_data)  # log probabilities\n",
    "\n",
    "# Step 2: Generate Precision-Recall data\n",
    "# Use raw log probabilities as the \"scores\" for the classifier\n",
    "precision, recall, thresholds = precision_recall_curve(cv_data_y, -log_probs_cv)  \n",
    "# Negative log_probs because lower values indicate anomalies\n",
    "\n",
    "# Step 3: Compute the area under the PR curve\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Step 4: Plot the Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.', label=f'GMM (AUC = {pr_auc:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for GMM Anomaly Detection')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd969ff9-a54e-42c6-ab60-8829d17927e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Step 1: Compute log-likelihoods for validation data\n",
    "log_probs_cv = gmm.score_samples(cv_data)  # log probabilities\n",
    "\n",
    "# Step 2: Compute precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(cv_data_y, -log_probs_cv)\n",
    "\n",
    "# Step 3: Plot precision and recall vs. threshold\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision[:-1], label='Precision', color='blue')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall', color='orange')\n",
    "plt.xlabel('Threshold (-t)')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ef374-8449-4ddf-b66b-9cd8f2a74b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "t =-30\n",
    "print(\"t = \", t)\n",
    "\n",
    "# Step 1: Compute log-likelihoods for validation data\n",
    "log_probs_cv = gmm.score_samples(cv_data)  # log probabilities\n",
    "log_probs_test = gmm.score_samples(test_data)\n",
    "\n",
    "# Step 2: Classify based on threshold 't'\n",
    "# Anomaly if log_prob < t â†’ 1 (anomaly), else 0 (normal)\n",
    "pred_cv = (log_probs_cv < t).astype(int)\n",
    "pred_test = (log_probs_test < t).astype(int)\n",
    "\n",
    "# Step 3: Calculate accuracy\n",
    "accuracy = accuracy_score(cv_data_y, pred_cv)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58dfac3-7481-41ab-a9fb-9c4f291fbee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test_data_y, pred_test)\n",
    "row_sum = cnf_matrix.sum(axis=1,keepdims=True)\n",
    "cnf_matrix_norm =cnf_matrix  / row_sum \n",
    "sns.heatmap(cnf_matrix_norm,cmap='YlGnBu',annot=True)\n",
    "plt.title(\"Normalized Confusion Matrix - Test data\")\n",
    "# Set axis labels\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9d018-437f-4620-9ba9-81dd4bc64e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming test_data_y and pred_test are numpy arrays or pandas Series\n",
    "# Example: test_data_y = np.array([...]), pred_test = np.array([...])\n",
    "\n",
    "# Compute counts for each category\n",
    "TP = np.sum((test_data_y == 1) & (pred_test == 1))  # True positives\n",
    "TN = np.sum((test_data_y == 0) & (pred_test == 0))  # True negatives\n",
    "FP = np.sum((test_data_y == 0) & (pred_test == 1))  # False positives\n",
    "FN = np.sum((test_data_y == 1) & (pred_test == 0))  # False negatives\n",
    "\n",
    "P = np.sum((test_data_y==1))\n",
    "N = np.sum((test_data_y==0))\n",
    "LP = np.sum((pred_test == 1))\n",
    "LN = np.sum((pred_test == 0))\n",
    "# Total number of samples\n",
    "total = len(test_data_y)\n",
    "\n",
    "# Compute percentages\n",
    "TP_percent = TP / total * 100\n",
    "TN_percent = TN / total * 100\n",
    "FP_percent = FP / total * 100\n",
    "FN_percent = FN / total * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"True Positives: {TP} / {P}\")\n",
    "print(f\"False Negatives: {FN} / {P}\")\n",
    "print(f\"True Negatives: {TN} / {N}\")\n",
    "print(f\"False Positives: {FP} / {N}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
