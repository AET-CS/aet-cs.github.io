{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5648bfa7-470a-451e-8f7c-98d9191ad526",
   "metadata": {},
   "source": [
    "# Perceptron learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e138ec5f-ba0d-46b8-b985-72a12bc55158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615818a-c57f-4ddc-abe9-6c43a436c97f",
   "metadata": {},
   "source": [
    "Perceptron learning is an iterative algorithm that converges to the appropriate weights for a single perceptron, given a learnable training set. If the training set is not learnable, the algorithm will not converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67fb04-a352-4982-89a8-c34705739dd5",
   "metadata": {},
   "source": [
    "**Perceptron Learning Algorithm**\n",
    "\n",
    "Given a dataset $X$ of $m$ observations $x \\in \\mathcal{R}^{1 \\times n}$, an outcome vector $y \\in \\mathcal{R}^{m \\times 1}$, we wish to find a weight vector $w \\in \\mathcal{R}^{n \\times 1}$ such that $y_i = A(\\mathbf{x}_i \\cdot \\mathbf{w})$ for each $0 \\leq i < m$. In matrix form: $A(\\mathbf{X} \\mathbf{w}) = \\mathbf{y}$. The last element of each observation vector $\\mathbf{x}$ will be -1 to account for the bias term.\n",
    "\n",
    "1. Initialize $ \\mathbf{w} $ as a random vector.\n",
    "2. **For each epoch**:\n",
    "    - For each $ (\\mathbf{x}_i, y_i)$ in the training set:\n",
    "      - Compute $ \\hat{y} = A(\\mathbf{x}_i \\cdot \\mathbf{w}) $.\n",
    "      - Update $ \\mathbf{w} $ as:\n",
    "        $$\n",
    "        \\mathbf{w} \\leftarrow \\mathbf{w} + (y_i - \\hat{y}) \\lambda \\mathbf{x}_i\n",
    "        $$\n",
    "3. Compute accuracy:\n",
    "   $$\n",
    "   \\text{accuracy} = 1 - \\frac{\\sum_i |f(\\mathbf{x}_i) - A(\\mathbf{x}_i \\cdot \\mathbf{w})|}{\\text{len}(\\text{training\\_set})}\n",
    "   $$\n",
    "4. Return $ (\\mathbf{w}, \\text{accuracy}) $.\n",
    "\n",
    "The learning rate $\\lambda$ determines the rate of convergence. In practice $\\lambda$ can be close to, but not greater than, 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3e9ea-87f9-4b22-97df-b54918996b18",
   "metadata": {},
   "source": [
    "We'll define the data set as a matrix $X$ and a vector $y$ using numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1450bbf4-1e27-4d96-9de7-18e62c6c7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset corresponding to boolean AND. \n",
    "\n",
    "X = np.array([\n",
    "    [0, 0, -1],\n",
    "    [0, 1, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 1, -1]\n",
    "])\n",
    "y = np.array([[0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "98493883-d308-4ea0-8900-d481779bd988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0c13c656-6e0e-400f-8e72-bf4fa1207425",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The heaviside step function\n",
    "\n",
    "def A(x):\n",
    "    return np.heaviside(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7ad7d52f-b438-4649-8ea3-7c25b29b2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "62de5354-c33d-4421-bf91-333fc9b0078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 -1]] [[0.]]\n",
      "[[ 0  1 -1]] [[0.]]\n",
      "[[ 1  0 -1]] [[0.]]\n",
      "[[ 1  1 -1]] [[1.]]\n"
     ]
    }
   ],
   "source": [
    "for j in range(100):\n",
    "    i = j%4\n",
    "    x = X[i:i+1]\n",
    "    fx = y[0,i]\n",
    "    y_hat = A(x @ w)\n",
    "    w = w + r*(fx - y_hat)*x.T\n",
    "\n",
    "for j in range(4):\n",
    "    i = j%4\n",
    "    x = X[i:i+1]\n",
    "    fx = y[0,i]\n",
    "    y_hat = A(x @ w)\n",
    "    print(x, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "67d9d35a-528e-4a60-b363-9413438b281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random((3,1))\n",
    "all_w = []\n",
    "r = 1\n",
    "for epoch in range(200):\n",
    "    for i in range(4):\n",
    "        x = X[i:i+1]\n",
    "        fx = y[0,i]\n",
    "        y_hat = A(x @ w)\n",
    "        w = w + r*(fx - y_hat)*x.T\n",
    "        all_w += [w[0:2]]\n",
    "    accuracy = 1 - np.sum(np.abs(A(X@w)  - y.T))/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab507d-25dd-42ba-a5b5-e83f37d8e4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
