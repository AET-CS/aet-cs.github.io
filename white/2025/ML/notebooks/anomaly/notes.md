## üìö Anomaly Detection
**Course:** Machine‚ÄëLearning ‚Äì Anomaly Detection & Imbalanced Data

**Topic:** Using **SMOTE** for balancing and **Gaussian‚ÄëMixture Models (GMMs)** for anomaly detection on a credit‚Äëcard fraud data set.

---

### 1. Overview of the Two Notebooks

| Notebook                                  | Main Goal                                                                                                   | Key Techniques                                                                                                                                                    |
| ----------------------------------------- | ----------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **SMOTE Notebook**                        | Re‚Äëbalance a heavily imbalanced binary classification problem (e.g., fraud vs. legit).                      | ‚Ä¢‚ÄØSMOTE (Synthetic Minority Over‚Äësampling Technique)  <br>‚Ä¢‚ÄØTrain / test split  <br>‚Ä¢‚ÄØStandard classification models (SVM, Logistic Regression, Decision Tree, ‚Ä¶) |
| **Gaussian‚ÄëMixture Model (GMM) Notebook** | Detect anomalies (fraud) by modelling *only* the normal class and flagging points that don‚Äôt fit the model. | ‚Ä¢‚ÄØUnsupervised GMM clustering <br>‚Ä¢‚ÄØFeature‚Äëdistribution visualisation <br>‚Ä¢‚ÄØThreshold tuning for anomaly scores <br>‚Ä¢‚ÄØPrecision / Recall / F1 evaluation         |

Both notebooks work on the same **credit‚Äëcard‚Äëtransactions** data set (the Kaggle ‚ÄúCredit Card Fraud Detection‚Äù data set, 28 anonymised *V* features + `Amount` + `Class`).

---

### 2. SMOTE ‚Äì Synthetic Minority Over‚Äësampling Technique

#### 2.1 What SMOTE Does

1. **Identify a minority (positive) point** ‚Äì e.g. a known fraudulent transaction.
2. **Find its *k* nearest minority neighbours** (default‚ÄØ=‚ÄØ5).
3. **Randomly pick one neighbour** and draw a line between the two points.
4. **Sample a point on that line** (by a random interpolation factor‚ÄØ‚àà‚ÄØ[0,1]).
5. **Add the synthetic point to the training set**.

Repeat until the desired class balance is reached (often a 50/50 split).

> **Key Insight:** SMOTE *creates* new minority examples **inside** the feature space spanned by real minority points, rather than just copying them.

#### 2.2 Correct Workflow

```
1Ô∏è‚É£  Split original data ‚Üí train / test (e.g. 80/20).
2Ô∏è‚É£  **Apply SMOTE only on the TRAINING data** ‚Üí balanced_train.
3Ô∏è‚É£  Fit any classifier on balanced_train.
4Ô∏è‚É£  Evaluate on the ORIGINAL TEST set (still imbalanced!).
```

*Never* SMOTE the test set ‚Äì otherwise the evaluation would be on synthetic data whose true label you do not know.

#### 2.3 Common Pitfalls

| Pitfall                        | Why it‚Äôs a problem                                                                                               | Fix                                                                                                          |
| ------------------------------ | ---------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ |
| SMOTE on test data             | Inflates performance, creates ‚Äúfake‚Äù positives.                                                                  | Keep test data untouched.                                                                                    |
| Ignoring feature correlation   | SMOTE works in the raw feature space; if features are highly correlated the synthetic points may be unrealistic. | Optionally use **SMOTE‚ÄëENN** or **SMOTE‚ÄëTomek** to clean noisy synthetic samples.                            |
| Over‚Äëbalancing ‚Üí large dataset | Too many synthetic points can make training slow.                                                                | Choose a modest oversampling ratio (e.g., 100‚ÄØ% of minority size) or use **class_weight** on the classifier. |

---

### 3. Gaussian‚ÄëMixture Models (GMM) for Anomaly Detection

#### 3.1 Intuition

- A **Gaussian mixture** assumes the data is generated by a **weighted sum of multivariate normal distributions** (components).
- In 1‚ÄëD you could picture several bell‚Äëshaped curves stacked together.
- In high‚Äëdimensional space each component is a *cluster* (a ‚Äúblob‚Äù) having its own **mean vector** and **covariance matrix**.

```
p(x) = Œ£_{c=1}^{C} œÄ_c  ¬∑ ùí©(x | Œº_c, Œ£_c)
œÄ_c ‚â• 0,   Œ£_c œÄ_c = 1
```

#### 3.2 Why GMMs are Good for Anomaly Detection

1. **Unsupervised on the *normal* class** ‚Äì you only train on ‚Äúgood‚Äù transactions.
2. The model learns the *density* of normal data.
3. **Anomaly score** = ‚Äìlog‚ÄØlikelihood under the mixture. Low likelihood ‚Üí likely anomaly.
4. The score is *continuous* ‚Üí you can choose any threshold that balances **Recall** (catching fraud) vs **False‚ÄëPositive Rate** (inconveniencing customers).

#### 3.3 Typical GMM Anomaly‚ÄëDetection Pipeline

```
1Ô∏è‚É£  Split data ‚Üí train / test (no labels needed for training!).
2Ô∏è‚É£  Train GMM **only on the NORMAL (Class=0)** training rows.
3Ô∏è‚É£  Compute log‚Äëlikelihood for every point (train & test).
4Ô∏è‚É£  Choose a threshold œÑ.  Points with score < œÑ are flagged as anomalies.
5Ô∏è‚É£  Evaluate against the true labels (only for reporting):  TP, FP, FN, TN ‚Üí precision, recall, F1, ‚Ä¶
```

> **Important:** Do **not** mix the fraudulent class into the GMM training ‚Äì otherwise the model will *learn* that fraud is ‚Äúnormal‚Äù.

#### 3.4 Parameters to Play With

| Parameter                                               | Effect                                                                                                              | Typical range                                              |
| ------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- |
| `n_components` (number of Gaussians)                    | Controls model flexibility. Too few ‚Üí under‚Äëfit (high false negatives). Too many ‚Üí over‚Äëfit (high false positives). | 1‚ÄØ‚Äì‚ÄØ10 (use BIC/AIC to select).                            |
| `covariance_type` (`full`, `tied`, `diag`, `spherical`) | Shape of each component‚Äôs covariance. `full` is most expressive but slower.                                         | Start with `diag`.                                         |
| `threshold` (or equivalently a *z‚Äëscore*)               | Moves the decision line left/right. Higher threshold ‚Üí catch more fraud but also more false alarms.                 | Sweep over a fine grid (e.g., 0.1‚ÄØ‚Äì‚ÄØ10).                   |
| Feature selection                                       | Removing noisy columns (e.g., V3 in the notes) improves density estimation.                                         | Keep only variables with clear separation (e.g., V5, V12). |

---

### 4. Feature‚ÄëDistribution Visualisation

- Plot each feature **separately** for *normal* vs *fraud* rows (kernel‚Äëdensity estimate or histogram).
- Look for **clear separation** (e.g., V5 may show distinct peaks).
- Features that *overlap heavily* (e.g., V3) can be **dropped** because they add noise to the GMM.

---

### 5. Evaluation & the ‚ÄúQuotient‚Äù Metric

The notebooks report a custom **ratio** (let‚Äôs call it *Fraud‚ÄëCapture‚ÄëEfficiency*):

```
ratio = TP / (TP + FP)      # aka precision for the fraud class
```

- **Goal**: maximise the ratio while keeping an acceptable **Recall** (TP / (TP + FN)).
- The baseline in the notebook gave ‚âà‚ÄØ4‚ÄØ% ‚Äì i.e. only 4‚ÄØ% of flagged cases were actually fraud.
- By tweaking `n_components`, the decision threshold, and the selected features you can push this far higher (often >‚ÄØ40‚ÄØ% on the Kaggle data set).

---

### 6. Quick Summary

| Concept               | What to Remember                                                                                                                 |
| --------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| **SMOTE**             | Synthetic oversampling *only on training data* ‚Üí balanced dataset ‚Üí any classifier works.                                        |
| **GMM**               | Unsupervised density model on normal data ‚Üí continuous anomaly scores ‚Üí easy threshold tuning.                                   |
| **Feature‚Äëselection** | Visualise per‚Äëfeature distributions; keep those that separate classes.                                                           |
| **Evaluation**        | Use precision, recall, F1, *and* the custom ratio (TP/(TP+FP)).                                                                  |
| **Tuning**            | `n_components`, `covariance_type`, threshold, and selected features are the levers.                                              |
| **Practical tip**     | Start with a simple 2‚ÄëD synthetic example, verify SMOTE & GMM behaviours, then move to the real 28‚Äëdimensional credit‚Äëcard data. |
